# rat15_srnn_tuning.yaml
experiment:
  name: "rat15_srnn_tuning_longer_dwell"
  description: "Hyperparameter tuning for Rat15 with longer discrete state dwell times."
  seed: 0
  mode: "unsupervised"

data:
  rat_id: 15
  data_root: "/content/drive/MyDrive/rSLDS"
  outputs_root: "/content/drive/MyDrive/sRNN/sRNN-Model-Outputs"
  subset: "responsive"
  h5_optional: false

model:
  K_states: 3
  latent_dim: 8          # can still change across runs
  kappa: 3.0             # ↑ was 1.0 → more self-transition bias = longer dwell
  use_inputs: true

dr:
  method: "dca1"
  n_components: 16
  random_state: 0

training:
  num_iters: 1000
  window_size: 50        # can still change across runs
  stride: 10
  tbptt_steps: 100
  batch_size: 64
  lr: 5e-4               # can still change across runs
  overwrite: true
  verbose: true
  test_split: 0.2
  ms_per_sample: 100
  rate_mode: "mean"

  shock_expand_sec: 0.5  # ↓ was 1.0 → shocks influence transitions for a shorter period
  u_scale: 1.0           # ↓ was 1.5 → inputs less aggressively force switches

initialization:
  warmup_epochs: 200
  lambda_entropy: 1e-5   # slightly conservative → less “noisy” transitions
  lambda_usage: 5e-3     # ↓ from 1e-2 in previous config → less pressure to over-use states

evaluation:
  prediction_horizons: [10, 20, 30, 40]

rslds_init:
  path: "/content/drive/MyDrive/RSLDS_SRNN/ModelOutputs/BehaviouralModelrSLDS/Rat{rat_id}/behav_rslds_dropNaN_K3_D1_it12000_z_hat.npy"
  use_head: 300

# Optional: built-in search grid if your script supports it
search:
  kappa: [2.0, 3.0, 4.0]
  lr: [5e-4, 3e-4]
  window_size: [40, 50, 75]
